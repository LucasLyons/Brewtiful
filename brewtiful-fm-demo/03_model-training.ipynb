{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae23a78",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "**Notebook 3: Model Training**\n",
    "\n",
    "This notebook trains two LightFM models using Optuna for hyperparameter optimization:\n",
    "1. **Baseline model**: collaborative filtering only (user-item interactions)\n",
    "2. **Feature-enhanced model**: adds item features (beer style + brewery)\n",
    "\n",
    "LightFM uses matrix factorization with WARP/BPR loss to learn user and item embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33427349",
   "metadata": {},
   "source": [
    "**NOTE: This training sequence uses the `lightfm-next` package to allow forwards-compatibility with python 3.10+ which the base LightFM package lacks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6285fe",
   "metadata": {},
   "source": [
    "### Discusssion on Feature Selection\n",
    "\n",
    "The first model will not use item features, making it a pure matrix factorization (MF) model which corresponds to the SVD model. This model will only train on interaction (rating) data. The second model will learn brewery and style metadata embeddings, which should be informative/contain useful signals as some users will prefer beers from certain breweries or styles. The item features should also improve the item-item similarity results. Based on the results of our EDA, we want to avoid giving the model weak/noisy signals as the data is already sparse. Therefore, we've opted to not engineer or use additional features. For example, we'll leave out ABV as it is most likely a noisy variable to include. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0d886",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33aa014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kitsuragi/Desktop/Code/Brewtiful/.venv/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import LightFM and evaluation libraries\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightfm\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from lightfm import LightFM\n",
    "from lightfm import data\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score, reciprocal_rank\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unidecode import unidecode # to deal with accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed train/val/test splits + datasets\n",
    "train = pd.read_parquet('data/train.parquet', engine='pyarrow')\n",
    "val = pd.read_parquet('data/val.parquet', engine='pyarrow')\n",
    "test = pd.read_parquet('data/test.parquet', engine='pyarrow')\n",
    "filtered = pd.read_parquet('data/filtered.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296993e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LightFM Dataset object for ID mapping\n",
    "light_data = lightfm.data.Dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39cc184",
   "metadata": {},
   "source": [
    "### LightFM Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8688b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to fit the dataset with all users and items in the training set\n",
    "light_data = lightfm.data.Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c3c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we'll create a list of all unique item features (styles + breweries)\n",
    "metadata = list(set(filtered['style'].unique()).union(set(filtered['brewery'].unique())))\n",
    "# Now, fit the dataset with users, items, and item features from the training set\n",
    "light_data.fit(users=filtered['user'].unique(),\n",
    "               items=filtered['beer_id'].unique(),\n",
    "               item_features=metadata)\n",
    "# Store item mappings for later use\n",
    "user_mappings = light_data._user_id_mapping\n",
    "item_mappings = light_data._item_id_mapping\n",
    "inv_user_mappings = {v:k for k, v in user_mappings.items()}\n",
    "inv_item_mappings = {v:k for k, v in item_mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba15749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build interaction matrices with sample weights from rating bins\n",
    "# Train uses weights (0, 0.01, 0.09, 0.9), validation is binary\n",
    "train_interactions = light_data.build_interactions(train[['user', 'beer_id', 'weight_all']].values)\n",
    "val_interactions = light_data.build_interactions(val[['user', 'beer_id']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75119313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kitsuragi/Desktop/Code/Brewtiful/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Construct item feature matrix with helper function\n",
    "from helpers.training import construct_item_features\n",
    "features = construct_item_features(light_data, filtered, b=.2, s=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a28d0ed",
   "metadata": {},
   "source": [
    "### Optimization with Optuna\n",
    "\n",
    "We'll use the `optuna` library to optimize our model with intelligent hyperparameter searching and trial pruning.\n",
    "\n",
    "**Objective**: Maximize Precision@50 on validation set\n",
    "\n",
    "We'll optimize over precision@50 because Brewtiful displays many recommendations at once, coming from diverse style categories. We want to not only show one or two highly relevant items, but multiple relevant items across different categories. 50 should be a sufficiently high k to ensure that we're optimizing the model to select many relevant items.\n",
    "\n",
    "We'll train models both with and without item features to see if the item features help.\n",
    "\n",
    "**Hyperparameters to Optimize**:\n",
    "- no_components: The dimensionality of the feature latent embeddings\n",
    "- learning_schedule: One of (‘adagrad’, ‘adadelta’)\n",
    "- loss: Loss function. We'll test both WARP and BPR (both popular loss functions, but WARP usually performs better when precision is the goal).\n",
    "- learning_rate: Initial learning rate for the adagrad learning schedule.\n",
    "- item_alpha: L2 penalty on item features.\n",
    "- user_alpha: L2 penalty on user features.\n",
    "- max_sampled: Maximum number of negative samples used during WARP fitting.\n",
    "- epochs: Number of epochs to run model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e735da",
   "metadata": {},
   "source": [
    "#### No Item Features (Pure MF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3688bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 17:54:49,488] A new study created in memory with name: no-name-e5cedf27-a494-43f1-9ac5-770b05a11f7f\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from helpers.training import create_objective\n",
    "\n",
    "\n",
    "# Initialize the study\n",
    "init_study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40ae8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 17:55:37,165] Trial 0 finished with value: 0.1568261981010437 and parameters: {'no_components': 10, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 1e-10, 'user_alpha': 1e-10, 'learning_rate': 0.05, 'max_sampled': 10, 'epochs': 20}. Best is trial 0 with value: 0.1568261981010437.\n",
      "[I 2025-11-08 17:56:43,948] Trial 1 finished with value: 0.1551637202501297 and parameters: {'no_components': 24, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.6388328509503195e-08, 'user_alpha': 2.3479280663625877e-07, 'rho': 0.992726554945493, 'epsilon': 4.6781797360102236e-07, 'max_sampled': 7, 'epochs': 29}. Best is trial 0 with value: 0.1568261981010437.\n",
      "[I 2025-11-08 17:58:05,561] Trial 2 finished with value: 0.06811082363128662 and parameters: {'no_components': 26, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'item_alpha': 1.69489840914113e-07, 'user_alpha': 1.3200287339041189e-10, 'learning_rate': 0.5511291329402712, 'epochs': 32}. Best is trial 0 with value: 0.1568261981010437.\n",
      "[I 2025-11-08 18:00:09,674] Trial 3 finished with value: 0.16275398433208466 and parameters: {'no_components': 60, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.4199383813819772e-09, 'user_alpha': 4.563722163288271e-10, 'rho': 0.9392676246096697, 'epsilon': 2.3370893558306795e-08, 'max_sampled': 14, 'epochs': 38}. Best is trial 3 with value: 0.16275398433208466.\n",
      "[I 2025-11-08 18:02:45,341] Trial 4 finished with value: 0.16693535447120667 and parameters: {'no_components': 126, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.082340405785837e-08, 'user_alpha': 8.923893471132795e-07, 'rho': 0.9079587356038152, 'epsilon': 6.798014468996422e-08, 'max_sampled': 11, 'epochs': 34}. Best is trial 4 with value: 0.16693535447120667.\n",
      "[I 2025-11-08 18:02:57,662] Trial 5 pruned. \n",
      "[I 2025-11-08 18:03:16,323] Trial 6 pruned. \n",
      "[I 2025-11-08 18:03:32,775] Trial 7 pruned. \n",
      "[I 2025-11-08 18:03:52,704] Trial 8 pruned. \n",
      "[I 2025-11-08 18:04:49,951] Trial 9 pruned. \n",
      "[I 2025-11-08 18:08:42,831] Trial 10 finished with value: 0.1720067262649536 and parameters: {'no_components': 125, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.311257093797117e-07, 'user_alpha': 5.5829799172677285e-08, 'rho': 0.9049541118958679, 'epsilon': 8.421159595417498e-08, 'max_sampled': 14, 'epochs': 48}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:12:55,149] Trial 11 finished with value: 0.17047859728336334 and parameters: {'no_components': 127, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.558969550326489e-07, 'user_alpha': 6.466996275880595e-08, 'rho': 0.9030217573350326, 'epsilon': 1.0094679979054355e-07, 'max_sampled': 15, 'epochs': 50}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:15:49,566] Trial 12 pruned. \n",
      "[I 2025-11-08 18:18:29,191] Trial 13 pruned. \n",
      "[I 2025-11-08 18:20:59,015] Trial 14 pruned. \n",
      "[I 2025-11-08 18:23:40,250] Trial 15 pruned. \n",
      "[I 2025-11-08 18:25:45,669] Trial 16 pruned. \n",
      "[I 2025-11-08 18:26:03,951] Trial 17 pruned. \n",
      "[I 2025-11-08 18:27:45,628] Trial 18 pruned. \n",
      "[I 2025-11-08 18:28:06,335] Trial 19 pruned. \n",
      "[I 2025-11-08 18:30:30,303] Trial 20 pruned. \n",
      "[I 2025-11-08 18:30:51,699] Trial 21 pruned. \n",
      "[I 2025-11-08 18:33:10,406] Trial 22 finished with value: 0.1686817705631256 and parameters: {'no_components': 127, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.618826911370114e-08, 'user_alpha': 3.7287785954065044e-07, 'rho': 0.9086326119539615, 'epsilon': 1.1433199541103073e-07, 'max_sampled': 11, 'epochs': 28}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:35:07,507] Trial 23 finished with value: 0.16811083257198334 and parameters: {'no_components': 115, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.218083409647123e-08, 'user_alpha': 3.4885353873614514e-07, 'rho': 0.9258406969763051, 'epsilon': 1.517771330040394e-07, 'max_sampled': 14, 'epochs': 25}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:35:23,495] Trial 24 pruned. \n",
      "[I 2025-11-08 18:35:45,458] Trial 25 pruned. \n",
      "[I 2025-11-08 18:36:04,632] Trial 26 pruned. \n",
      "[I 2025-11-08 18:39:04,501] Trial 27 finished with value: 0.16980688273906708 and parameters: {'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.29113094908743e-07, 'user_alpha': 4.521985389225149e-08, 'rho': 0.9000957782772175, 'epsilon': 2.4452127599962984e-07, 'max_sampled': 14, 'epochs': 37}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:41:44,267] Trial 28 pruned. \n",
      "[I 2025-11-08 18:42:06,589] Trial 29 pruned. \n",
      "[I 2025-11-08 18:43:33,680] Trial 30 pruned. \n",
      "[I 2025-11-08 18:46:00,295] Trial 31 finished with value: 0.170797660946846 and parameters: {'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.281836049774706e-07, 'user_alpha': 1.8803669555017234e-07, 'rho': 0.9122166895236752, 'epsilon': 1.5651612033478642e-07, 'max_sampled': 12, 'epochs': 30}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:48:24,555] Trial 32 pruned. \n",
      "[I 2025-11-08 18:51:09,424] Trial 33 pruned. \n",
      "[I 2025-11-08 18:51:23,340] Trial 34 pruned. \n",
      "[I 2025-11-08 18:54:14,689] Trial 35 pruned. \n",
      "[I 2025-11-08 18:54:36,913] Trial 36 pruned. \n",
      "[I 2025-11-08 18:55:01,435] Trial 37 pruned. \n",
      "[I 2025-11-08 18:55:23,590] Trial 38 pruned. \n",
      "[I 2025-11-08 18:55:45,381] Trial 39 pruned. \n",
      "[I 2025-11-08 18:57:54,625] Trial 40 finished with value: 0.16784214973449707 and parameters: {'no_components': 121, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.550880636504189e-09, 'user_alpha': 5.857730648207921e-07, 'rho': 0.9184919033641382, 'epsilon': 2.4014339681983166e-07, 'max_sampled': 10, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 18:58:16,592] Trial 41 pruned. \n",
      "[I 2025-11-08 18:58:38,004] Trial 42 pruned. \n",
      "[I 2025-11-08 18:59:41,033] Trial 43 pruned. \n",
      "[I 2025-11-08 19:01:34,526] Trial 44 pruned. \n",
      "[I 2025-11-08 19:02:16,897] Trial 45 pruned. \n",
      "[I 2025-11-08 19:02:39,269] Trial 46 pruned. \n",
      "[I 2025-11-08 19:02:57,317] Trial 47 pruned. \n",
      "[I 2025-11-08 19:03:49,410] Trial 48 pruned. \n",
      "[I 2025-11-08 19:06:06,567] Trial 49 pruned. \n",
      "[I 2025-11-08 19:06:47,817] Trial 50 pruned. \n",
      "[I 2025-11-08 19:08:40,422] Trial 51 finished with value: 0.16795970499515533 and parameters: {'no_components': 115, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.0046420871092204e-07, 'user_alpha': 3.3485056471463756e-07, 'rho': 0.9252584997866802, 'epsilon': 1.4881191399957355e-07, 'max_sampled': 14, 'epochs': 24}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:10:15,182] Trial 52 finished with value: 0.16764064133167267 and parameters: {'no_components': 128, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.48466857106685e-07, 'user_alpha': 4.161419975819416e-07, 'rho': 0.9050646099817805, 'epsilon': 2.9304712945397584e-07, 'max_sampled': 13, 'epochs': 20}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:12:18,160] Trial 53 finished with value: 0.1683795154094696 and parameters: {'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.3222769571007e-08, 'user_alpha': 1.383578968563761e-07, 'rho': 0.9117437168176621, 'epsilon': 1.885436477307179e-07, 'max_sampled': 12, 'epochs': 27}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:14:30,366] Trial 54 finished with value: 0.16854743659496307 and parameters: {'no_components': 124, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.1859089095154708e-08, 'user_alpha': 9.161423417973522e-08, 'rho': 0.9138520126126713, 'epsilon': 1.9706157060252264e-07, 'max_sampled': 12, 'epochs': 28}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:16:50,250] Trial 55 finished with value: 0.1683795154094696 and parameters: {'no_components': 124, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.041769219574102e-09, 'user_alpha': 7.939147860323913e-08, 'rho': 0.9196538894934625, 'epsilon': 2.3446725702280743e-07, 'max_sampled': 12, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:17:14,154] Trial 56 pruned. \n",
      "[I 2025-11-08 19:17:38,549] Trial 57 pruned. \n",
      "[I 2025-11-08 19:19:47,677] Trial 58 pruned. \n",
      "[I 2025-11-08 19:20:05,159] Trial 59 pruned. \n",
      "[I 2025-11-08 19:20:24,566] Trial 60 pruned. \n",
      "[I 2025-11-08 19:21:30,519] Trial 61 pruned. \n",
      "[I 2025-11-08 19:23:32,792] Trial 62 finished with value: 0.1683795154094696 and parameters: {'no_components': 112, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.9893251305226976e-09, 'user_alpha': 6.189313780893333e-08, 'rho': 0.9093313136456853, 'epsilon': 2.7400078652086897e-07, 'max_sampled': 12, 'epochs': 28}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:23:56,748] Trial 63 pruned. \n",
      "[I 2025-11-08 19:24:20,204] Trial 64 pruned. \n",
      "[I 2025-11-08 19:24:42,693] Trial 65 pruned. \n",
      "[I 2025-11-08 19:26:13,392] Trial 66 pruned. \n",
      "[I 2025-11-08 19:26:35,430] Trial 67 pruned. \n",
      "[I 2025-11-08 19:26:55,454] Trial 68 pruned. \n",
      "[I 2025-11-08 19:27:51,815] Trial 69 pruned. \n",
      "[I 2025-11-08 19:28:34,188] Trial 70 pruned. \n",
      "[I 2025-11-08 19:30:46,817] Trial 71 finished with value: 0.1694878190755844 and parameters: {'no_components': 125, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.657302912765338e-09, 'user_alpha': 7.81708220937091e-08, 'rho': 0.9202779088452615, 'epsilon': 2.3189363054604096e-07, 'max_sampled': 12, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:31:09,513] Trial 72 pruned. \n",
      "[I 2025-11-08 19:31:31,944] Trial 73 pruned. \n",
      "[I 2025-11-08 19:31:46,715] Trial 74 pruned. \n",
      "[I 2025-11-08 19:32:08,823] Trial 75 pruned. \n",
      "[I 2025-11-08 19:32:32,115] Trial 76 pruned. \n",
      "[I 2025-11-08 19:33:02,299] Trial 77 pruned. \n",
      "[I 2025-11-08 19:33:26,406] Trial 78 pruned. \n",
      "[I 2025-11-08 19:33:50,891] Trial 79 pruned. \n",
      "[I 2025-11-08 19:35:45,759] Trial 80 pruned. \n",
      "[I 2025-11-08 19:38:05,606] Trial 81 finished with value: 0.16960537433624268 and parameters: {'no_components': 125, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.725628236893679e-09, 'user_alpha': 8.18631597906028e-08, 'rho': 0.9196715675153662, 'epsilon': 2.359088681041599e-07, 'max_sampled': 12, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:40:22,924] Trial 82 finished with value: 0.16801008582115173 and parameters: {'no_components': 126, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.115019866932247e-09, 'user_alpha': 6.535814420787728e-08, 'rho': 0.9215804844091597, 'epsilon': 2.420176691023727e-07, 'max_sampled': 11, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:40:47,746] Trial 83 pruned. \n",
      "[I 2025-11-08 19:42:19,643] Trial 84 pruned. \n",
      "[I 2025-11-08 19:42:43,294] Trial 85 pruned. \n",
      "[I 2025-11-08 19:44:40,017] Trial 86 finished with value: 0.1686817705631256 and parameters: {'no_components': 116, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 4.365060453855083e-09, 'user_alpha': 1.3294347592393343e-07, 'learning_rate': 0.022454255382544235, 'max_sampled': 14, 'epochs': 24}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:45:00,827] Trial 87 pruned. \n",
      "[I 2025-11-08 19:46:12,688] Trial 88 pruned. \n",
      "[I 2025-11-08 19:46:47,467] Trial 89 pruned. \n",
      "[I 2025-11-08 19:47:09,847] Trial 90 pruned. \n",
      "[I 2025-11-08 19:47:32,839] Trial 91 pruned. \n",
      "[I 2025-11-08 19:49:39,327] Trial 92 finished with value: 0.16957178711891174 and parameters: {'no_components': 123, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.650801741728464e-07, 'user_alpha': 3.9945667435621305e-08, 'rho': 0.9023803595596691, 'epsilon': 3.306291407241062e-07, 'max_sampled': 11, 'epochs': 26}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:51:34,283] Trial 93 finished with value: 0.16937027871608734 and parameters: {'no_components': 122, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 7.226202958677641e-07, 'user_alpha': 4.2802515270276015e-08, 'rho': 0.9022112073190351, 'epsilon': 3.21477481001047e-07, 'max_sampled': 11, 'epochs': 25}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:53:18,751] Trial 94 finished with value: 0.16884970664978027 and parameters: {'no_components': 122, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.99546125692027e-07, 'user_alpha': 3.7120892255851533e-08, 'rho': 0.9020076550581831, 'epsilon': 3.333962005933128e-07, 'max_sampled': 10, 'epochs': 23}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:53:30,737] Trial 95 pruned. \n",
      "[I 2025-11-08 19:55:17,499] Trial 96 pruned. \n",
      "[I 2025-11-08 19:55:30,595] Trial 97 pruned. \n",
      "[I 2025-11-08 19:57:21,391] Trial 98 finished with value: 0.16809402406215668 and parameters: {'no_components': 122, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.882152932008138e-07, 'user_alpha': 1.3360273817814337e-08, 'rho': 0.9007667874454397, 'epsilon': 3.305637301630295e-07, 'max_sampled': 11, 'epochs': 25}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 19:58:50,214] Trial 99 pruned. \n",
      "[I 2025-11-08 19:59:34,161] Trial 100 pruned. \n",
      "[I 2025-11-08 20:01:19,392] Trial 101 finished with value: 0.17041140794754028 and parameters: {'no_components': 117, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.003758652126634e-07, 'user_alpha': 6.842308026984687e-08, 'rho': 0.9095511871272655, 'epsilon': 3.0630936543188666e-07, 'max_sampled': 11, 'epochs': 24}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:03:34,324] Trial 102 pruned. \n",
      "[I 2025-11-08 20:05:02,877] Trial 103 pruned. \n",
      "[I 2025-11-08 20:07:09,781] Trial 104 finished with value: 0.16920235753059387 and parameters: {'no_components': 122, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.35891190340921e-07, 'user_alpha': 4.642894147730255e-08, 'rho': 0.9067392258012856, 'epsilon': 2.461858262281709e-07, 'max_sampled': 11, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:08:51,693] Trial 105 finished with value: 0.16856423020362854 and parameters: {'no_components': 123, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.803386461961349e-07, 'user_alpha': 5.5341588573396116e-08, 'rho': 0.9067758133896185, 'epsilon': 4.938314120882634e-07, 'max_sampled': 11, 'epochs': 21}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:09:14,319] Trial 106 pruned. \n",
      "[I 2025-11-08 20:09:39,530] Trial 107 pruned. \n",
      "[I 2025-11-08 20:10:28,757] Trial 108 pruned. \n",
      "[I 2025-11-08 20:11:59,450] Trial 109 pruned. \n",
      "[I 2025-11-08 20:12:42,527] Trial 110 pruned. \n",
      "[I 2025-11-08 20:13:06,047] Trial 111 pruned. \n",
      "[I 2025-11-08 20:13:30,997] Trial 112 pruned. \n",
      "[I 2025-11-08 20:14:09,015] Trial 113 pruned. \n",
      "[I 2025-11-08 20:14:31,548] Trial 114 pruned. \n",
      "[I 2025-11-08 20:14:54,420] Trial 115 pruned. \n",
      "[I 2025-11-08 20:16:55,249] Trial 116 pruned. \n",
      "[I 2025-11-08 20:17:18,132] Trial 117 pruned. \n",
      "[I 2025-11-08 20:18:48,519] Trial 118 pruned. \n",
      "[I 2025-11-08 20:19:07,277] Trial 119 pruned. \n",
      "[I 2025-11-08 20:20:23,924] Trial 120 pruned. \n",
      "[I 2025-11-08 20:20:44,549] Trial 121 pruned. \n",
      "[I 2025-11-08 20:21:07,509] Trial 122 pruned. \n",
      "[I 2025-11-08 20:21:32,781] Trial 123 pruned. \n",
      "[I 2025-11-08 20:21:57,330] Trial 124 pruned. \n",
      "[I 2025-11-08 20:22:17,196] Trial 125 pruned. \n",
      "[I 2025-11-08 20:22:41,309] Trial 126 pruned. \n",
      "[I 2025-11-08 20:23:04,870] Trial 127 pruned. \n",
      "[I 2025-11-08 20:23:29,343] Trial 128 pruned. \n",
      "[I 2025-11-08 20:26:07,401] Trial 129 finished with value: 0.1689336746931076 and parameters: {'no_components': 118, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.971268916511668e-09, 'user_alpha': 1.1152409817228915e-07, 'rho': 0.9102221364240018, 'epsilon': 2.5423794086051784e-07, 'max_sampled': 15, 'epochs': 31}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:26:29,926] Trial 130 pruned. \n",
      "[I 2025-11-08 20:29:03,387] Trial 131 finished with value: 0.16745592653751373 and parameters: {'no_components': 124, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.966519006607754e-09, 'user_alpha': 1.0840450157883475e-07, 'rho': 0.9077158152690166, 'epsilon': 2.8553703914743017e-07, 'max_sampled': 15, 'epochs': 31}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:30:42,125] Trial 132 pruned. \n",
      "[I 2025-11-08 20:33:03,374] Trial 133 finished with value: 0.16770781576633453 and parameters: {'no_components': 117, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.494536732276909e-09, 'user_alpha': 1.6752205936529218e-07, 'rho': 0.9125120987334281, 'epsilon': 3.578212339413187e-07, 'max_sampled': 14, 'epochs': 29}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:35:51,860] Trial 134 finished with value: 0.16713686287403107 and parameters: {'no_components': 126, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.5990379745780427e-09, 'user_alpha': 2.011853743210976e-10, 'rho': 0.9162732047757177, 'epsilon': 2.0311142638405991e-07, 'max_sampled': 15, 'epochs': 32}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:36:13,409] Trial 135 pruned. \n",
      "[I 2025-11-08 20:36:35,643] Trial 136 pruned. \n",
      "[I 2025-11-08 20:38:36,753] Trial 137 pruned. \n",
      "[I 2025-11-08 20:38:57,819] Trial 138 pruned. \n",
      "[I 2025-11-08 20:39:23,403] Trial 139 pruned. \n",
      "[I 2025-11-08 20:39:46,613] Trial 140 pruned. \n",
      "[I 2025-11-08 20:41:18,806] Trial 141 finished with value: 0.16804365813732147 and parameters: {'no_components': 123, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.74095447838959e-07, 'user_alpha': 5.719722941362437e-08, 'rho': 0.9068739402159327, 'epsilon': 5.462480765019429e-07, 'max_sampled': 11, 'epochs': 20}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:42:59,192] Trial 142 finished with value: 0.16690176725387573 and parameters: {'no_components': 120, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.91290117942231e-07, 'user_alpha': 4.48606183743493e-08, 'rho': 0.9072323363169179, 'epsilon': 3.7590121465577146e-07, 'max_sampled': 11, 'epochs': 22}. Best is trial 10 with value: 0.1720067262649536.\n",
      "[I 2025-11-08 20:44:50,353] Trial 143 pruned. \n",
      "[I 2025-11-08 20:46:39,720] Trial 144 pruned. \n",
      "[I 2025-11-08 20:47:03,067] Trial 145 pruned. \n",
      "[I 2025-11-08 20:49:03,222] Trial 146 pruned. \n",
      "[I 2025-11-08 20:50:38,872] Trial 147 pruned. \n",
      "[I 2025-11-08 20:51:00,202] Trial 148 pruned. \n",
      "[I 2025-11-08 20:52:52,985] Trial 149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_components : 125\n",
      "learning_schedule : adadelta\n",
      "loss : warp\n",
      "item_alpha : 9.311257093797117e-07\n",
      "user_alpha : 5.5829799172677285e-08\n",
      "rho : 0.9049541118958679\n",
      "epsilon : 8.421159595417498e-08\n",
      "max_sampled : 14\n",
      "epochs : 48\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for BASELINE model (no item features)\n",
    "# Parameters tuned: embedding size, learning rate, regularization, loss function, epochs\n",
    "# Starting from sensible defaults, then exploring 150 trials\n",
    "# Uses WARP loss (Weighted Approximate-Rank Pairwise) for ranking optimization\n",
    "\n",
    "# Add in our original hyperparmeter values as a starting point for Optuna\n",
    "init_study.enqueue_trial(params={\"no_components\":10, \n",
    "                            \t\t\t\t\t\"learning_schedule\":'adagrad', \n",
    "                            \t\t\t\t\t\"loss\":'warp',\n",
    "                            \t\t\t\t\t\"learning_rate\":0.05,\n",
    "                            \t\t\t\t\t\"item_alpha\":1e-10, \n",
    "                            \t\t\t\t\t\"user_alpha\":1e-10, \n",
    "                            \t\t\t\t\t\"max_sampled\":10,\n",
    "                            \t\t\t\t\t\"epochs\":20})\n",
    "\n",
    "\n",
    "# Run the optimisation        \n",
    "init_study.optimize(create_objective(train_interactions=train_interactions[0], \n",
    "                                val_interactions=val_interactions[0], sample_weight=train_interactions[1], \n",
    "                                use_item_features=False, p_k=50, loss=['warp', 'bpr'],  enable_pruning=True, pruning_interval=5), \n",
    "                                n_trials=150)\n",
    "\n",
    "# Save the best parameters\n",
    "best_params = init_study.best_params\n",
    "for k, v in best_params.items():\n",
    "    print(k,\":\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37070d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best parameters for later use\n",
    "import pickle\n",
    "with open('artifacts/best_params_no_item_features.pkl', 'wb') as f:\n",
    "    pickle.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83226591",
   "metadata": {},
   "source": [
    "#### Item Features\n",
    "\n",
    "This model will not only learn identity embeddings for every user and item, but will also learn embeddings for breweries and styles. However, LightFM gives all features equal weighting by default. It's critical to allow for optimization over the weighting of item features, as the default weighting is likely much too high, hiding the item's unique signal behind their metadata features. We want the metadata features to complement the identity features, not overpower them.\n",
    "\n",
    "**Additional Hyperparameters**:\n",
    "- b: relative weight of brewery embeddings to identity features\n",
    "- s: relative weight of style embeddings to identity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ba206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 20:52:53,005] A new study created in memory with name: no-name-9440778e-1df3-4f90-b778-bc9e7f7087f3\n"
     ]
    }
   ],
   "source": [
    "# Initialize new Optuna study for ITEM FEATURES model\n",
    "# Define the study\n",
    "item_feature_study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8f8698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-08 20:53:50,874] Trial 0 finished with value: 0.167170450091362 and parameters: {'no_components': 10, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 1e-10, 'user_alpha': 1e-10, 'learning_rate': 0.05, 'max_sampled': 10, 'epochs': 20, 'b': 0.2, 's': 0.1}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 20:56:17,983] Trial 1 finished with value: 0.15205709636211395 and parameters: {'no_components': 23, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 7.778230385925488e-08, 'user_alpha': 1.3340496799811835e-07, 'learning_rate': 0.011022614761051925, 'max_sampled': 8, 'epochs': 49, 'b': 0.13145230121577267, 's': 0.10554380763123505}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 20:57:43,401] Trial 2 finished with value: 0.09924433380365372 and parameters: {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'item_alpha': 6.0004869947923865e-09, 'user_alpha': 4.774202949111062e-07, 'learning_rate': 0.7437413531463639, 'epochs': 21, 'b': 0.009546524509794485, 's': 0.4592307921276593}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 21:01:34,845] Trial 3 finished with value: 0.13904282450675964 and parameters: {'no_components': 109, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'item_alpha': 7.106019446694072e-08, 'user_alpha': 1.4132048469079696e-07, 'rho': 0.9094743301832312, 'epsilon': 8.039907662763597e-07, 'epochs': 37, 'b': 0.15869155688011544, 's': 0.011483263467517268}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 21:03:56,904] Trial 4 finished with value: 0.09672544151544571 and parameters: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'item_alpha': 2.852658575692568e-07, 'user_alpha': 1.4558577235076775e-09, 'rho': 0.9835350957105682, 'epsilon': 5.8207887440849164e-08, 'epochs': 42, 'b': 0.4025047813299463, 's': 0.27910445080916824}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 21:04:19,138] Trial 5 pruned. \n",
      "[I 2025-11-08 21:07:02,780] Trial 6 finished with value: 0.16406382620334625 and parameters: {'no_components': 115, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 2.8380093461511934e-07, 'user_alpha': 9.312681763873423e-07, 'learning_rate': 0.029106355662785584, 'max_sampled': 5, 'epochs': 36, 'b': 0.3841125434560458, 's': 0.4452332835486226}. Best is trial 0 with value: 0.167170450091362.\n",
      "[I 2025-11-08 21:12:15,308] Trial 7 finished with value: 0.16784214973449707 and parameters: {'no_components': 120, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.32499538790255e-09, 'user_alpha': 6.238549166353575e-09, 'rho': 0.9071340220290647, 'epsilon': 6.80509843574182e-08, 'max_sampled': 14, 'epochs': 47, 'b': 0.39879240154585727, 's': 0.4871764815047911}. Best is trial 7 with value: 0.16784214973449707.\n",
      "[I 2025-11-08 21:12:36,795] Trial 8 pruned. \n",
      "[I 2025-11-08 21:13:01,309] Trial 9 pruned. \n",
      "[I 2025-11-08 21:17:39,410] Trial 10 finished with value: 0.17598657310009003 and parameters: {'no_components': 94, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.338713450502908e-09, 'user_alpha': 9.939228801032114e-09, 'rho': 0.9472663667968243, 'epsilon': 1.0837124444255111e-07, 'max_sampled': 15, 'epochs': 49, 'b': 0.49394971540032356, 's': 0.3183369114449941}. Best is trial 10 with value: 0.17598657310009003.\n",
      "[I 2025-11-08 21:22:15,403] Trial 11 finished with value: 0.1829555183649063 and parameters: {'no_components': 93, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.225353670489775e-09, 'user_alpha': 1.1142172998756116e-08, 'rho': 0.954768094128093, 'epsilon': 1.0717207960942534e-07, 'max_sampled': 15, 'epochs': 50, 'b': 0.49521683828173474, 's': 0.3310451965845828}. Best is trial 11 with value: 0.1829555183649063.\n",
      "[I 2025-11-08 21:26:05,587] Trial 12 finished with value: 0.18102435767650604 and parameters: {'no_components': 91, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.2031485005743029e-09, 'user_alpha': 1.7777737712006745e-08, 'rho': 0.955787366876068, 'epsilon': 2.447550936593309e-07, 'max_sampled': 13, 'epochs': 42, 'b': 0.49778574156531336, 's': 0.34169591364044094}. Best is trial 11 with value: 0.1829555183649063.\n",
      "[I 2025-11-08 21:29:35,840] Trial 13 finished with value: 0.18152813613414764 and parameters: {'no_components': 88, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.1759960341524206e-09, 'user_alpha': 4.484553092824163e-08, 'rho': 0.962033296111989, 'epsilon': 3.436966063900659e-07, 'max_sampled': 13, 'epochs': 42, 'b': 0.4791568456317663, 's': 0.3559409863134123}. Best is trial 11 with value: 0.1829555183649063.\n",
      "[I 2025-11-08 21:33:05,956] Trial 14 finished with value: 0.19126786291599274 and parameters: {'no_components': 86, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.23224379724779e-10, 'user_alpha': 4.3864547328525746e-08, 'rho': 0.9624596106524076, 'epsilon': 3.4305127230745035e-07, 'max_sampled': 12, 'epochs': 42, 'b': 0.3115376666815325, 's': 0.3736915411104159}. Best is trial 14 with value: 0.19126786291599274.\n",
      "[I 2025-11-08 21:36:08,830] Trial 15 finished with value: 0.1881612092256546 and parameters: {'no_components': 81, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.3977505311866214e-08, 'user_alpha': 1.8744547517388963e-09, 'rho': 0.9769640530041286, 'epsilon': 1.800156761120212e-07, 'max_sampled': 12, 'epochs': 39, 'b': 0.3031947408172752, 's': 0.39255052235904225}. Best is trial 14 with value: 0.19126786291599274.\n",
      "[I 2025-11-08 21:38:36,244] Trial 16 finished with value: 0.16985727846622467 and parameters: {'no_components': 75, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.4647357257285285e-08, 'user_alpha': 2.281479951328008e-09, 'rho': 0.9951778482922811, 'epsilon': 3.8405248818774604e-07, 'max_sampled': 12, 'epochs': 33, 'b': 0.3079720727544808, 's': 0.38907684386495023}. Best is trial 14 with value: 0.19126786291599274.\n",
      "[I 2025-11-08 21:41:02,237] Trial 17 finished with value: 0.19958019256591797 and parameters: {'no_components': 43, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.2563572336347594e-08, 'user_alpha': 2.620502422468931e-10, 'rho': 0.9753052263763747, 'epsilon': 9.881785793715373e-07, 'max_sampled': 11, 'epochs': 39, 'b': 0.31878084057465567, 's': 0.25507749289587434}. Best is trial 17 with value: 0.19958019256591797.\n",
      "[I 2025-11-08 21:41:22,709] Trial 18 pruned. \n",
      "[I 2025-11-08 21:43:32,025] Trial 19 finished with value: 0.1956339329481125 and parameters: {'no_components': 40, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.311152487906049e-07, 'user_alpha': 4.3165512830907636e-10, 'rho': 0.9703225974987548, 'epsilon': 9.912725074069039e-07, 'max_sampled': 8, 'epochs': 40, 'b': 0.23697497633382905, 's': 0.1824814256301539}. Best is trial 17 with value: 0.19958019256591797.\n",
      "[I 2025-11-08 21:45:41,918] Trial 20 finished with value: 0.1996641606092453 and parameters: {'no_components': 30, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 7.568086968119454e-07, 'user_alpha': 4.469356805841121e-10, 'rho': 0.976952527257092, 'epsilon': 9.88428628291016e-07, 'max_sampled': 8, 'epochs': 39, 'b': 0.22906511626288018, 's': 0.1654066271168597}. Best is trial 20 with value: 0.1996641606092453.\n",
      "[I 2025-11-08 21:47:54,778] Trial 21 finished with value: 0.20688499510288239 and parameters: {'no_components': 34, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.083977379061554e-07, 'user_alpha': 3.6636362872018554e-10, 'rho': 0.9772421477978408, 'epsilon': 8.971365879923543e-07, 'max_sampled': 8, 'epochs': 39, 'b': 0.240669412227396, 's': 0.15696923284956407}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 21:49:58,506] Trial 22 finished with value: 0.19177161157131195 and parameters: {'no_components': 29, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.204000134406663e-07, 'user_alpha': 2.5425158658040094e-10, 'rho': 0.9928775220545454, 'epsilon': 6.036142004636833e-07, 'max_sampled': 8, 'epochs': 38, 'b': 0.21627450954213978, 's': 0.148565202569228}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 21:50:13,186] Trial 23 pruned. \n",
      "[I 2025-11-08 21:52:53,146] Trial 24 finished with value: 0.1996641606092453 and parameters: {'no_components': 37, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.5316584935787224e-08, 'user_alpha': 2.095786495200475e-10, 'rho': 0.9714865179102034, 'epsilon': 9.973906607922434e-07, 'max_sampled': 10, 'epochs': 45, 'b': 0.3628403243663351, 's': 0.15525966728669421}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 21:53:10,966] Trial 25 pruned. \n",
      "[I 2025-11-08 21:53:31,734] Trial 26 pruned. \n",
      "[I 2025-11-08 21:55:23,793] Trial 27 finished with value: 0.1889168918132782 and parameters: {'no_components': 54, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.645639166968184e-08, 'user_alpha': 1.6342676269660912e-10, 'rho': 0.9675927161080285, 'epsilon': 2.4813943821921406e-07, 'max_sampled': 9, 'epochs': 30, 'b': 0.17540628300930974, 's': 0.1639101956584466}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 21:58:00,312] Trial 28 finished with value: 0.19210748374462128 and parameters: {'no_components': 50, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.184838188420298e-07, 'user_alpha': 6.992033737722924e-10, 'rho': 0.9809382756955503, 'epsilon': 6.162750949237307e-07, 'max_sampled': 9, 'epochs': 43, 'b': 0.433809495313384, 's': 0.2116911314643813}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 21:58:14,357] Trial 29 pruned. \n",
      "[I 2025-11-08 21:58:30,673] Trial 30 pruned. \n",
      "[I 2025-11-08 22:00:54,823] Trial 31 finished with value: 0.19958017766475677 and parameters: {'no_components': 44, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.138304228869112e-08, 'user_alpha': 2.875459109837566e-10, 'rho': 0.9735626335684853, 'epsilon': 9.75594402628001e-07, 'max_sampled': 11, 'epochs': 39, 'b': 0.27668548478892674, 's': 0.23539832890919507}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 22:03:16,782] Trial 32 finished with value: 0.20327456295490265 and parameters: {'no_components': 34, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.180717228889152e-09, 'user_alpha': 5.507947582902179e-10, 'rho': 0.9725720262195107, 'epsilon': 9.716844106107956e-07, 'max_sampled': 9, 'epochs': 44, 'b': 0.34853689914052544, 's': 0.256163448568096}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 22:05:53,645] Trial 33 finished with value: 0.19731318950653076 and parameters: {'no_components': 31, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.3190851577471765e-09, 'user_alpha': 5.626183016359251e-10, 'rho': 0.9658372151784058, 'epsilon': 6.247493678776256e-07, 'max_sampled': 9, 'epochs': 48, 'b': 0.3524535258469195, 's': 0.2918703422297324}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 22:06:07,640] Trial 34 pruned. \n",
      "[I 2025-11-08 22:06:24,485] Trial 35 pruned. \n",
      "[I 2025-11-08 22:06:39,014] Trial 36 pruned. \n",
      "[I 2025-11-08 22:06:59,405] Trial 37 pruned. \n",
      "[I 2025-11-08 22:09:07,342] Trial 38 finished with value: 0.1996641457080841 and parameters: {'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.350313952942346e-07, 'user_alpha': 1.081798322743118e-09, 'rho': 0.9726753834215008, 'epsilon': 7.707505855290202e-07, 'max_sampled': 8, 'epochs': 41, 'b': 0.10340767352958088, 's': 0.2240680172083825}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 22:09:26,334] Trial 39 pruned. \n",
      "[I 2025-11-08 22:10:26,222] Trial 40 pruned. \n",
      "[I 2025-11-08 22:12:32,743] Trial 41 finished with value: 0.1981528103351593 and parameters: {'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.6584702596097277e-07, 'user_alpha': 1.1845758799106698e-09, 'rho': 0.9737673723118537, 'epsilon': 7.463197142155555e-07, 'max_sampled': 8, 'epochs': 41, 'b': 0.08575439142769548, 's': 0.23567044955900943}. Best is trial 21 with value: 0.20688499510288239.\n",
      "[I 2025-11-08 22:14:39,266] Trial 42 finished with value: 0.20806047320365906 and parameters: {'no_components': 24, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.4603380170069663e-07, 'user_alpha': 6.095974925752614e-10, 'rho': 0.9885563432288218, 'epsilon': 7.309892317610287e-07, 'max_sampled': 8, 'epochs': 44, 'b': 0.11662928860410568, 's': 0.20910626078895314}. Best is trial 42 with value: 0.20806047320365906.\n",
      "[I 2025-11-08 22:16:58,928] Trial 43 finished with value: 0.21654072403907776 and parameters: {'no_components': 24, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.515976309473182e-07, 'user_alpha': 5.825022148853556e-10, 'rho': 0.9879345178287267, 'epsilon': 5.113215108815841e-07, 'max_sampled': 9, 'epochs': 46, 'b': 0.007409324190958827, 's': 0.13878064831056564}. Best is trial 43 with value: 0.21654072403907776.\n",
      "[I 2025-11-08 22:19:17,459] Trial 44 finished with value: 0.2099076360464096 and parameters: {'no_components': 20, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.505226005355263e-07, 'user_alpha': 4.847872406492906e-10, 'rho': 0.9903699747171597, 'epsilon': 5.140736676719293e-07, 'max_sampled': 9, 'epochs': 47, 'b': 0.002658436855286604, 's': 0.11714749102113861}. Best is trial 43 with value: 0.21654072403907776.\n",
      "[I 2025-11-08 22:21:41,195] Trial 45 finished with value: 0.21133501827716827 and parameters: {'no_components': 21, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.2384262329303625e-07, 'user_alpha': 6.433108192582721e-10, 'rho': 0.9889602786429355, 'epsilon': 2.87216382612059e-07, 'max_sampled': 9, 'epochs': 50, 'b': 0.019025146791125186, 's': 0.12272628437858575}. Best is trial 43 with value: 0.21654072403907776.\n",
      "[I 2025-11-08 22:21:57,407] Trial 46 pruned. \n",
      "[I 2025-11-08 22:22:10,699] Trial 47 pruned. \n",
      "[I 2025-11-08 22:24:32,384] Trial 48 finished with value: 0.21796810626983643 and parameters: {'no_components': 25, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.7740271206941776e-07, 'user_alpha': 1.6100171517102546e-09, 'rho': 0.987760074030315, 'epsilon': 5.370312705316461e-07, 'max_sampled': 9, 'epochs': 47, 'b': 0.045519011077795865, 's': 0.09190007348536669}. Best is trial 48 with value: 0.21796810626983643.\n",
      "[I 2025-11-08 22:27:07,778] Trial 49 finished with value: 0.21687659621238708 and parameters: {'no_components': 25, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.285743653661479e-08, 'user_alpha': 5.517294440264552e-09, 'rho': 0.9883086244384947, 'epsilon': 1.790475262041138e-07, 'max_sampled': 11, 'epochs': 49, 'b': 0.032987219995774864, 's': 0.08524459381101415}. Best is trial 48 with value: 0.21796810626983643.\n",
      "[I 2025-11-08 22:27:34,339] Trial 50 pruned. \n",
      "[I 2025-11-08 22:30:03,541] Trial 51 finished with value: 0.22023507952690125 and parameters: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.1533671253274534e-07, 'user_alpha': 8.025566837491608e-09, 'rho': 0.9876857035018662, 'epsilon': 1.746314618658939e-07, 'max_sampled': 10, 'epochs': 48, 'b': 0.03693668046888321, 's': 0.02732576430055131}. Best is trial 51 with value: 0.22023507952690125.\n",
      "[I 2025-11-08 22:32:27,118] Trial 52 finished with value: 0.21603696048259735 and parameters: {'no_components': 18, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.1184682417968165e-07, 'user_alpha': 7.71373090525535e-09, 'rho': 0.9855056573370868, 'epsilon': 1.5966797921042014e-07, 'max_sampled': 10, 'epochs': 48, 'b': 0.025425424538343427, 's': 0.027607051107047732}. Best is trial 51 with value: 0.22023507952690125.\n",
      "[I 2025-11-08 22:35:04,242] Trial 53 finished with value: 0.22703611850738525 and parameters: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.903416023824005e-08, 'user_alpha': 7.556387490634186e-09, 'rho': 0.9840580345660526, 'epsilon': 1.5333083083015913e-07, 'max_sampled': 11, 'epochs': 49, 'b': 0.02968838891423302, 's': 0.032037128949092546}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 22:37:37,837] Trial 54 finished with value: 0.2214105874300003 and parameters: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 7.572532965456497e-08, 'user_alpha': 7.162818713831089e-09, 'rho': 0.9841402530285778, 'epsilon': 1.4625194725631466e-07, 'max_sampled': 11, 'epochs': 48, 'b': 0.05090546523247846, 's': 0.029591755177324305}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 22:41:31,168] Trial 55 pruned. \n",
      "[I 2025-11-08 22:44:16,377] Trial 56 finished with value: 0.2168765664100647 and parameters: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.409854851101771e-07, 'user_alpha': 1.2147317668583257e-08, 'rho': 0.9934283174388112, 'epsilon': 9.068150478124987e-08, 'max_sampled': 13, 'epochs': 49, 'b': 0.0690114860283925, 's': 0.08321346446875935}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 22:44:33,245] Trial 57 pruned. \n",
      "[I 2025-11-08 22:44:49,423] Trial 58 pruned. \n",
      "[I 2025-11-08 22:47:54,617] Trial 59 finished with value: 0.2163728028535843 and parameters: {'no_components': 46, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.439622595295866e-08, 'user_alpha': 5.61538406512444e-09, 'rho': 0.980475640095981, 'epsilon': 1.2829070506542663e-07, 'max_sampled': 13, 'epochs': 49, 'b': 0.042813596797271106, 's': 0.05680764397469832}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 22:48:14,030] Trial 60 pruned. \n",
      "[I 2025-11-08 22:50:46,503] Trial 61 finished with value: 0.21897569298744202 and parameters: {'no_components': 27, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.46671787719612e-08, 'user_alpha': 1.347637776008787e-08, 'rho': 0.9933806437208353, 'epsilon': 9.168912545590193e-08, 'max_sampled': 11, 'epochs': 46, 'b': 0.03789297027767073, 's': 0.07286617322244007}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 22:52:58,074] Trial 62 pruned. \n",
      "[I 2025-11-08 22:53:12,804] Trial 63 pruned. \n",
      "[I 2025-11-08 22:55:33,551] Trial 64 pruned. \n",
      "[I 2025-11-08 22:58:35,515] Trial 65 finished with value: 0.2129303216934204 and parameters: {'no_components': 61, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.364710232710031e-07, 'user_alpha': 2.3497675345400053e-08, 'rho': 0.9918703064782824, 'epsilon': 2.0895154767573274e-07, 'max_sampled': 11, 'epochs': 47, 'b': 0.03730284783465749, 's': 0.10516504441490307}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:01:39,307] Trial 66 finished with value: 0.21595299243927002 and parameters: {'no_components': 38, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.596876952955217e-08, 'user_alpha': 1.5261766872028168e-08, 'rho': 0.9779524079495494, 'epsilon': 9.996904659044988e-08, 'max_sampled': 14, 'epochs': 50, 'b': 0.14354419875663038, 's': 0.03163626210238584}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:04:10,952] Trial 67 pruned. \n",
      "[I 2025-11-08 23:04:27,204] Trial 68 pruned. \n",
      "[I 2025-11-08 23:06:44,773] Trial 69 pruned. \n",
      "[I 2025-11-08 23:07:08,612] Trial 70 pruned. \n",
      "[I 2025-11-08 23:09:23,903] Trial 71 pruned. \n",
      "[I 2025-11-08 23:09:39,827] Trial 72 pruned. \n",
      "[I 2025-11-08 23:12:13,892] Trial 73 finished with value: 0.21771618723869324 and parameters: {'no_components': 29, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.9287585282682655e-07, 'user_alpha': 1.0545337728803039e-08, 'rho': 0.9908827694557103, 'epsilon': 2.0746171993018752e-07, 'max_sampled': 11, 'epochs': 47, 'b': 0.059834726678923034, 's': 0.06743250332653956}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:14:55,931] Trial 74 finished with value: 0.21343408524990082 and parameters: {'no_components': 31, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.3720417996684803e-07, 'user_alpha': 9.337076688776889e-09, 'rho': 0.9921320456854241, 'epsilon': 2.0678840913576095e-07, 'max_sampled': 12, 'epochs': 47, 'b': 0.06318491543725512, 's': 0.06811873095167852}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:17:48,423] Trial 75 pruned. \n",
      "[I 2025-11-08 23:20:16,980] Trial 76 finished with value: 0.2211587131023407 and parameters: {'no_components': 35, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.084295419609181e-08, 'user_alpha': 2.291751494211702e-08, 'rho': 0.9950922124662671, 'epsilon': 8.052109504090911e-08, 'max_sampled': 11, 'epochs': 45, 'b': 0.034509095398601294, 's': 0.050585008805390304}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:22:46,440] Trial 77 pruned. \n",
      "[I 2025-11-08 23:24:32,364] Trial 78 finished with value: 0.2168765664100647 and parameters: {'no_components': 34, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.539091522793293e-08, 'user_alpha': 2.5853628312551324e-08, 'rho': 0.9832761640573657, 'epsilon': 2.2569851889334695e-07, 'max_sampled': 11, 'epochs': 31, 'b': 0.03511243306152668, 's': 0.026124936241328237}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:24:51,357] Trial 79 pruned. \n",
      "[I 2025-11-08 23:27:10,860] Trial 80 pruned. \n",
      "[I 2025-11-08 23:27:28,424] Trial 81 pruned. \n",
      "[I 2025-11-08 23:29:50,705] Trial 82 pruned. \n",
      "[I 2025-11-08 23:31:12,671] Trial 83 finished with value: 0.21376994252204895 and parameters: {'no_components': 22, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.723001547549717e-07, 'user_alpha': 2.9873070564399497e-09, 'rho': 0.9915807756275036, 'epsilon': 1.7400871269710597e-07, 'max_sampled': 10, 'epochs': 26, 'b': 0.07544691202242061, 's': 0.037036495702156766}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:33:51,087] Trial 84 finished with value: 0.21729637682437897 and parameters: {'no_components': 31, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 7.06362038494506e-09, 'user_alpha': 4.4019267722225315e-09, 'rho': 0.9939969142589123, 'epsilon': 9.291215034458635e-08, 'max_sampled': 11, 'epochs': 48, 'b': 0.046676106095357314, 's': 0.06811069684886512}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:34:09,079] Trial 85 pruned. \n",
      "[I 2025-11-08 23:34:26,472] Trial 86 pruned. \n",
      "[I 2025-11-08 23:34:41,651] Trial 87 pruned. \n",
      "[I 2025-11-08 23:35:01,115] Trial 88 pruned. \n",
      "[I 2025-11-08 23:35:20,171] Trial 89 pruned. \n",
      "[I 2025-11-08 23:37:55,191] Trial 90 finished with value: 0.22535686194896698 and parameters: {'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.816777434144655e-09, 'user_alpha': 9.792105400302573e-09, 'rho': 0.9830732115676962, 'epsilon': 2.439056924687076e-07, 'max_sampled': 11, 'epochs': 48, 'b': 0.028414160127878445, 's': 0.042712021564180164}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:40:31,392] Trial 91 finished with value: 0.22695213556289673 and parameters: {'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.4360573687432918e-08, 'user_alpha': 9.618908602465326e-09, 'rho': 0.9821174077111036, 'epsilon': 2.6290989033613924e-07, 'max_sampled': 11, 'epochs': 48, 'b': 0.027531954651111808, 's': 0.038827466192332356}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:40:49,752] Trial 92 pruned. \n",
      "[I 2025-11-08 23:43:18,967] Trial 93 finished with value: 0.22308984398841858 and parameters: {'no_components': 29, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.746686971501153e-09, 'user_alpha': 1.9963351182591568e-08, 'rho': 0.9841646259382938, 'epsilon': 3.1777394376430385e-07, 'max_sampled': 10, 'epochs': 47, 'b': 0.01835446221801393, 's': 0.031697870184194225}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:45:30,413] Trial 94 finished with value: 0.22644837200641632 and parameters: {'no_components': 22, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.0346492628635875e-09, 'user_alpha': 2.0800631251859566e-08, 'rho': 0.9676360142656828, 'epsilon': 3.53974378050695e-07, 'max_sampled': 10, 'epochs': 44, 'b': 0.014853506742002916, 's': 0.005546758967517593}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:47:39,424] Trial 95 finished with value: 0.224853053689003 and parameters: {'no_components': 22, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.507909025847371e-09, 'user_alpha': 2.014032709909604e-08, 'rho': 0.9667613122640594, 'epsilon': 3.6247150533343113e-07, 'max_sampled': 10, 'epochs': 43, 'b': 0.014451510454918423, 's': 0.006950775550817038}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:49:43,901] Trial 96 finished with value: 0.2198992371559143 and parameters: {'no_components': 22, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 1.0332076589855312e-08, 'user_alpha': 2.2740676991034373e-08, 'learning_rate': 0.07579038262975928, 'max_sampled': 10, 'epochs': 43, 'b': 0.014694421584499292, 's': 0.006689475802223937}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:51:48,643] Trial 97 finished with value: 0.2254408299922943 and parameters: {'no_components': 22, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 9.265843991788325e-09, 'user_alpha': 5.39227646920853e-08, 'learning_rate': 0.11269476239193785, 'max_sampled': 10, 'epochs': 43, 'b': 0.013545823554504654, 's': 0.006892962484472195}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:53:50,861] Trial 98 finished with value: 0.21410579979419708 and parameters: {'no_components': 19, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 1.5054842224729644e-09, 'user_alpha': 5.501895057111214e-08, 'learning_rate': 0.16579264458409615, 'max_sampled': 10, 'epochs': 41, 'b': 0.023534790928586572, 's': 0.025804852250983227}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:54:05,303] Trial 99 pruned. \n",
      "[I 2025-11-08 23:54:19,483] Trial 100 pruned. \n",
      "[I 2025-11-08 23:56:24,487] Trial 101 pruned. \n",
      "[I 2025-11-08 23:58:27,907] Trial 102 finished with value: 0.2173803448677063 and parameters: {'no_components': 22, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 8.562655570590921e-09, 'user_alpha': 4.715279881264906e-08, 'learning_rate': 0.18234848000403905, 'max_sampled': 10, 'epochs': 42, 'b': 0.012750204535352073, 's': 0.008045644192134377}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-08 23:58:44,887] Trial 103 pruned. \n",
      "[I 2025-11-09 00:00:49,821] Trial 104 finished with value: 0.21570108830928802 and parameters: {'no_components': 23, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 9.273428797830428e-09, 'user_alpha': 3.0392531449616225e-08, 'learning_rate': 0.09871874626329209, 'max_sampled': 10, 'epochs': 41, 'b': 0.018949500484077317, 's': 0.0328770351143034}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:01:05,631] Trial 105 pruned. \n",
      "[I 2025-11-09 00:01:21,164] Trial 106 pruned. \n",
      "[I 2025-11-09 00:01:39,392] Trial 107 pruned. \n",
      "[I 2025-11-09 00:01:54,427] Trial 108 pruned. \n",
      "[I 2025-11-09 00:04:21,653] Trial 109 finished with value: 0.2181360423564911 and parameters: {'no_components': 27, 'learning_schedule': 'adagrad', 'loss': 'warp', 'item_alpha': 1.7551372773654795e-09, 'user_alpha': 8.19641546355803e-09, 'learning_rate': 0.1673945477560916, 'max_sampled': 11, 'epochs': 46, 'b': 0.0002687067182198903, 's': 0.020837705627836354}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:06:33,758] Trial 110 pruned. \n",
      "[I 2025-11-09 00:09:00,950] Trial 111 finished with value: 0.22367757558822632 and parameters: {'no_components': 33, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.39416541137296e-09, 'user_alpha': 9.518431963175856e-07, 'rho': 0.9609898797714574, 'epsilon': 3.8082271689229404e-07, 'max_sampled': 11, 'epochs': 45, 'b': 0.03687814482114077, 's': 0.0302846183425646}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:11:25,717] Trial 112 finished with value: 0.21796810626983643 and parameters: {'no_components': 32, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.393924767660693e-09, 'user_alpha': 1.7588102557825102e-07, 'rho': 0.9606664671127686, 'epsilon': 3.806940982356301e-07, 'max_sampled': 11, 'epochs': 45, 'b': 0.03384959063660776, 's': 0.026974834102997898}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:13:46,940] Trial 113 finished with value: 0.21872375905513763 and parameters: {'no_components': 33, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.3943740463363106e-09, 'user_alpha': 2.0208761443013825e-08, 'rho': 0.9672593311670152, 'epsilon': 3.6479174893920375e-07, 'max_sampled': 11, 'epochs': 42, 'b': 0.013090725448983091, 's': 0.034684386322786795}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:16:28,577] Trial 114 finished with value: 0.22233419120311737 and parameters: {'no_components': 40, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.9133480628913314e-09, 'user_alpha': 1.3626721843608849e-08, 'rho': 0.9702271595244056, 'epsilon': 3.0579317653007896e-07, 'max_sampled': 10, 'epochs': 49, 'b': 0.05866601573234659, 's': 0.013614719859295488}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:17:05,635] Trial 115 pruned. \n",
      "[I 2025-11-09 00:19:44,598] Trial 116 finished with value: 0.22283793985843658 and parameters: {'no_components': 39, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.2858063867882202e-09, 'user_alpha': 6.786126629608926e-07, 'rho': 0.9693076306031789, 'epsilon': 3.125449875621161e-07, 'max_sampled': 9, 'epochs': 49, 'b': 0.07967693563732645, 's': 0.014061853587479033}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:20:03,014] Trial 117 pruned. \n",
      "[I 2025-11-09 00:20:21,294] Trial 118 pruned. \n",
      "[I 2025-11-09 00:22:59,637] Trial 119 finished with value: 0.22006717324256897 and parameters: {'no_components': 37, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.051804737010797e-09, 'user_alpha': 2.9451601756276157e-07, 'rho': 0.9518282667198582, 'epsilon': 3.146072004003968e-07, 'max_sampled': 9, 'epochs': 50, 'b': 0.057548534099853915, 's': 0.022223041391262615}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:23:19,893] Trial 120 pruned. \n",
      "[I 2025-11-09 00:25:56,296] Trial 121 finished with value: 0.2226700335741043 and parameters: {'no_components': 35, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.861447701171924e-10, 'user_alpha': 5.876888684368652e-07, 'rho': 0.9720333961113624, 'epsilon': 3.4733122404949713e-07, 'max_sampled': 10, 'epochs': 48, 'b': 0.03970996768633147, 's': 0.01149609515724467}. Best is trial 53 with value: 0.22703611850738525.\n",
      "[I 2025-11-09 00:28:52,891] Trial 122 finished with value: 0.22795969247817993 and parameters: {'no_components': 51, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.014980518848715e-10, 'user_alpha': 6.542655570101786e-07, 'rho': 0.9705298516931289, 'epsilon': 3.5518501859598405e-07, 'max_sampled': 11, 'epochs': 48, 'b': 0.02790410929707462, 's': 0.001177178620838451}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:31:46,215] Trial 123 finished with value: 0.22048698365688324 and parameters: {'no_components': 54, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.142103673034411e-10, 'user_alpha': 7.668672454413169e-07, 'rho': 0.9700760941247553, 'epsilon': 3.3429304381723664e-07, 'max_sampled': 10, 'epochs': 48, 'b': 0.0251670288992554, 's': 0.012656033635810113}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:34:33,696] Trial 124 finished with value: 0.22258606553077698 and parameters: {'no_components': 50, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 6.278033566944486e-10, 'user_alpha': 3.997601486683694e-07, 'rho': 0.9749405856603097, 'epsilon': 3.5865567809023135e-07, 'max_sampled': 9, 'epochs': 50, 'b': 0.04436817056536335, 's': 0.010645848595170627}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:37:42,245] Trial 125 finished with value: 0.2239294797182083 and parameters: {'no_components': 70, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 7.181339178492072e-10, 'user_alpha': 5.021793867890736e-07, 'rho': 0.9745182492252564, 'epsilon': 3.662349233814798e-07, 'max_sampled': 9, 'epochs': 50, 'b': 0.04213686045022973, 's': 0.0005709635994079979}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:40:38,195] Trial 126 finished with value: 0.22233416140079498 and parameters: {'no_components': 64, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 5.789418552226059e-10, 'user_alpha': 4.0376600689474836e-07, 'rho': 0.9738101237035691, 'epsilon': 3.5212712646594353e-07, 'max_sampled': 8, 'epochs': 50, 'b': 0.025239862791814508, 's': 0.0021181504070957313}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:42:18,437] Trial 127 pruned. \n",
      "[I 2025-11-09 00:45:04,424] Trial 128 finished with value: 0.2211587131023407 and parameters: {'no_components': 56, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 3.7779250097928627e-10, 'user_alpha': 5.064741112494167e-07, 'rho': 0.9746922426550206, 'epsilon': 3.986699534114024e-07, 'max_sampled': 9, 'epochs': 47, 'b': 0.03949685191262698, 's': 0.0014673714199659443}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:45:27,611] Trial 129 pruned. \n",
      "[I 2025-11-09 00:45:47,908] Trial 130 pruned. \n",
      "[I 2025-11-09 00:48:23,457] Trial 131 pruned. \n",
      "[I 2025-11-09 00:49:05,013] Trial 132 pruned. \n",
      "[I 2025-11-09 00:51:57,384] Trial 133 finished with value: 0.21998320519924164 and parameters: {'no_components': 45, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 4.719613822577768e-10, 'user_alpha': 5.46186220987335e-07, 'rho': 0.9633432138014747, 'epsilon': 4.570144235562298e-07, 'max_sampled': 10, 'epochs': 49, 'b': 0.038474425312977296, 's': 0.02092128586263436}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:55:15,559] Trial 134 finished with value: 0.22460117936134338 and parameters: {'no_components': 84, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.8564787986509627e-09, 'user_alpha': 9.454025392773989e-07, 'rho': 0.9791215149029654, 'epsilon': 2.242380228250184e-07, 'max_sampled': 10, 'epochs': 48, 'b': 0.009400988742886049, 's': 0.00015206621051023963}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:58:39,060] Trial 135 finished with value: 0.22376154363155365 and parameters: {'no_components': 90, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.283319099751917e-10, 'user_alpha': 9.58115843553459e-07, 'rho': 0.9793903418976658, 'epsilon': 2.2549063336958547e-07, 'max_sampled': 10, 'epochs': 47, 'b': 0.010063948232056363, 's': 0.0012053527846982242}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 00:59:25,591] Trial 136 pruned. \n",
      "[I 2025-11-09 01:02:53,842] Trial 137 finished with value: 0.2268681824207306 and parameters: {'no_components': 85, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.136752869315583e-10, 'user_alpha': 6.798400321071565e-07, 'rho': 0.9777500702909145, 'epsilon': 2.677263526674358e-07, 'max_sampled': 10, 'epochs': 46, 'b': 0.012112352219582222, 's': 0.00255854163624336}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 01:07:46,685] Trial 138 finished with value: 0.22376154363155365 and parameters: {'no_components': 94, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.844762908326034e-10, 'user_alpha': 8.352537657838593e-07, 'rho': 0.9779306997033306, 'epsilon': 2.2727529395549825e-07, 'max_sampled': 11, 'epochs': 46, 'b': 0.013911529750207721, 's': 0.0027243948926213768}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 01:13:02,980] Trial 139 finished with value: 0.21947942674160004 and parameters: {'no_components': 94, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 8.584312711772246e-10, 'user_alpha': 7.416896383708718e-07, 'rho': 0.9823969079186986, 'epsilon': 2.689846042292012e-07, 'max_sampled': 11, 'epochs': 46, 'b': 0.013945757386290081, 's': 4.8900398647783345e-05}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 01:14:55,522] Trial 140 pruned. \n",
      "[I 2025-11-09 01:20:24,755] Trial 141 pruned. \n",
      "[I 2025-11-09 01:22:56,916] Trial 142 pruned. \n",
      "[I 2025-11-09 01:23:34,372] Trial 143 pruned. \n",
      "[I 2025-11-09 01:28:36,371] Trial 144 finished with value: 0.21780018508434296 and parameters: {'no_components': 82, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 2.443690099250595e-09, 'user_alpha': 8.630222226482963e-07, 'rho': 0.9827179200275914, 'epsilon': 4.011909677854027e-07, 'max_sampled': 11, 'epochs': 45, 'b': 0.015014577859675374, 's': 0.021751431417956456}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 01:29:44,147] Trial 145 pruned. \n",
      "[I 2025-11-09 01:33:07,181] Trial 146 finished with value: 0.22527286410331726 and parameters: {'no_components': 79, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.206144221029707e-09, 'user_alpha': 9.34550443200585e-07, 'rho': 0.9735673865808439, 'epsilon': 2.939068288831743e-07, 'max_sampled': 10, 'epochs': 47, 'b': 0.01579354115159193, 's': 0.000707467358112176}. Best is trial 122 with value: 0.22795969247817993.\n",
      "[I 2025-11-09 01:36:23,820] Trial 147 finished with value: 0.22972294688224792 and parameters: {'no_components': 75, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 9.854944294071034e-10, 'user_alpha': 9.565341504354942e-07, 'rho': 0.9444957056553378, 'epsilon': 2.878992523820034e-07, 'max_sampled': 11, 'epochs': 46, 'b': 0.009064583858183008, 's': 0.0005742885432749662}. Best is trial 147 with value: 0.22972294688224792.\n",
      "[I 2025-11-09 01:36:49,634] Trial 148 pruned. \n",
      "[I 2025-11-09 01:39:58,849] Trial 149 finished with value: 0.22325778007507324 and parameters: {'no_components': 75, 'learning_schedule': 'adadelta', 'loss': 'warp', 'item_alpha': 1.8844031939632065e-09, 'user_alpha': 3.1627465214872104e-07, 'rho': 0.9426852859455791, 'epsilon': 2.867565268351662e-07, 'max_sampled': 11, 'epochs': 45, 'b': 0.009489793901711415, 's': 0.010019021040943404}. Best is trial 147 with value: 0.22972294688224792.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_components : 75\n",
      "learning_schedule : adadelta\n",
      "loss : warp\n",
      "item_alpha : 9.854944294071034e-10\n",
      "user_alpha : 9.565341504354942e-07\n",
      "rho : 0.9444957056553378\n",
      "epsilon : 2.878992523820034e-07\n",
      "max_sampled : 11\n",
      "epochs : 46\n",
      "b : 0.009064583858183008\n",
      "s : 0.0005742885432749662\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for feature-enhanced model\n",
    "# Additional parameters: b (brewery weight), s (style weight)\n",
    "# These control how much style/brewery metadata influences embeddings\n",
    "\n",
    "# Add in our original hyperparmeter values as a starting point for Optuna\n",
    "item_feature_study.enqueue_trial(params={\"no_components\":10, \n",
    "                            \t\t\t\t\t\"learning_schedule\":'adagrad', \n",
    "                            \t\t\t\t\t\"loss\":'warp',\n",
    "                            \t\t\t\t\t\"learning_rate\":0.05,\n",
    "                            \t\t\t\t\t\"item_alpha\":1e-10, \n",
    "                            \t\t\t\t\t\"user_alpha\":1e-10, \n",
    "                            \t\t\t\t\t\"max_sampled\":10,\n",
    "                            \t\t\t\t\t\"epochs\":20,\n",
    "                                                \"b\": 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\"s\": 0.1})\n",
    "\n",
    "\n",
    "\n",
    "# Run the optimisation        \n",
    "item_feature_study.optimize(create_objective(train_interactions=train_interactions[0], \n",
    "                                val_interactions=val_interactions[0], sample_weight=train_interactions[1], \n",
    "                                p_k=10, use_item_features = True, light_data=light_data, dataset=filtered,\n",
    "                                loss=['warp', 'bpr'], enable_pruning=True, pruning_interval=5), \n",
    "                                n_trials=150)\n",
    "\n",
    "# Save the best parameters\n",
    "item_feature_best_params = item_feature_study.best_params\n",
    "for k, v in item_feature_best_params.items():\n",
    "    print(k,\":\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e299bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature-enhanced model parameters\n",
    "with open('artifacts/best_params_with_item_features.pkl', 'wb') as f:\n",
    "    pickle.dump(item_feature_best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.importance.get_param_importances(item_feature_study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
